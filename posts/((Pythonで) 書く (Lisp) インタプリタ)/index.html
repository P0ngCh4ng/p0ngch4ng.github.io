<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>((Pythonで) 書く (Lisp) インタプリタ)　を読んで</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/b19239382bd9f6e7.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b19239382bd9f6e7.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-7ee66019f7f6d30f.js" defer=""></script><script src="/_next/static/chunks/framework-db825bd0b4ae01ef.js" defer=""></script><script src="/_next/static/chunks/main-424107595f363128.js" defer=""></script><script src="/_next/static/chunks/pages/_app-deb173bd80cbaa92.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bid%5D-802f20735a68ccca.js" defer=""></script><script src="/_next/static/6psNSYDXPa_NtmbTZ86q2/_buildManifest.js" defer=""></script><script src="/_next/static/6psNSYDXPa_NtmbTZ86q2/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div>((Pythonで) 書く (Lisp) インタプリタ)　を読んで<br/>2022-11-15<br/><div><p>http://www.aoky.net/articles/peter_norvig/lispy.htm より
記事のまとめ...というより写経。</p>
<h2>schemeについて</h2>
<p>schemeは一般的にはlispの方言という説明を見かけたが、実態は違う言語である。
ここでlispの方言というのは、内包的な意味ではなく、単純に似た言語であるという意味にちかい。</p>
<p>今回の記事では、webページを読んで気づいたこと、写経などを行う。短い記事であるため、早ければ1ページ長くても２ページで終わる予定。
最終的には記事だけ残る。</p>
<h2>インタプリタの作成について</h2>
<pre><code>インタプリタは以下のような構成で作成される。
- 字句解析
- 構文解析
</code></pre>
<ul>
<li>
<p>構文実行
上の二つについてはまとめて論じらることもしばしばあるようだが、大まかにはこれらの大分がされる。</p>
<p>字句解析はインタプリタによって大きな違いはなく、与えられた文章を、字句ごとに分けることが目的である。
構文解析とは、字句解析の段階で最小になった文章の意味づけを理解していくフェーズである。</p>
<p>ここで、最小に分解された文字を、<strong>トークン</strong>と呼ぶ。
処理されたトークンは、構文解析のフェーズで解読され、最後に構文実行のフェーズで実行される。
インタプリタの言語ごとの差異は、ここで大きくなる。</p>
<p>基本的には、組み込み関数と文、それから式が実行される。</p>
</li>
</ul>
<h2>インタプリタを作成する</h2>
<h3>構文解析: readとparse</h3>
<pre><code>元の記事では、字句解析と構文解析が一緒くたになっているが、これは字句解析の実装が非常に簡単であったからであると思う。
というのも、字句解析においてはPythonのstr.splitをそのまま使っている。

```
def tokenize(s):
"文字列をトークンのリストに変換する。"
return s.replace('(',' ( ').replace(')',' ) ').split()
```
リスト１ 字句解析のプログラム

*()が多いため一見不思議な文に見えるが、()の間に空白を挟んでいるだけである。*

```
def read_from(tokens):
"トークンの列から式を読み込む。"
	if len(tokens) == 0:
		raise SyntaxError('unexpected EOF while reading')
	token = tokens.pop(0)
	if '(' == token:
		L = []
		while tokens[0] != ')':
			L.append(read_from(tokens))
		tokens.pop(0) # pop off ')'
		return L
	elif ')' == token:
		raise SyntaxError('unexpected )')
	else:
		return atom(token)

def atom(token):
"数は数にし、それ以外のトークンはシンボルにする。"
	try: return int(token)
	except ValueError:
		try: return float(token)
		except ValueError:
			return Symbol(token)
```
リスト2 構文解析のプログラム

read_from関数は、字句解析されたトークンが入力される。

lispでは、特別な構文は()しかなく、プログラム全体は必ず()に包まれる。
それら以外はすべてシンボルか数値である。
()の中を再帰的に処理し、トークンはそれぞれatom関数でシンボルか数値かどうか判定される。
シンボルはSymbolというオブジェクトに変換されるが、これはstrのエイリアスでしかなく、実態は後述するenvのなかに辞書の形で格納されている。
つまりここでSymbolオブジェクトは単なるキーとなる文字列である。

非常に簡素だが、Schemeの構文解析はこのように実装することができる。
</code></pre>
<h3>実行: eval</h3>
<pre><code>def eval(x, env=global_env):
    "環境の中で式を評価する。"
    if isa(x, Symbol):             # 変数参照
        return env.find(x)[x]
    elif not isa(x, list):         # 定数リテラル
        return x                
    elif x[0] == 'quote':          # (quote exp)
        (_, exp) = x
        return exp
    elif x[0] == 'if':             # (if test conseq alt)
        (_, test, conseq, alt) = x
        return eval((conseq if eval(test, env) else alt), env)
    elif x[0] == 'set!':           # (set! var exp)
        (_, var, exp) = x
        env.find(var)[var] = eval(exp, env)
    elif x[0] == 'define':         # (define var exp)
        (_, var, exp) = x
        env[var] = eval(exp, env)
		elif x[0] == 'lambda':         # (lambda (var*) exp)
        (_, vars, exp) = x
        return lambda *args: eval(exp, Env(vars, args, env))
    elif x[0] == 'begin':          # (begin exp*)
        for exp in x[1:]:
            val = eval(exp, env)
        return val
    else:                          # (proc exp*)
        exps = [eval(exp, env) for exp in x]
        proc = exps.pop(0)
        return proc(*exps)
 
isa = isinstance
 
Symbol = str
</code></pre>
<p>リスト3 構文実行のプログラム</p>
<p>構文解析によって処理されたプログラムは、ここで解釈される。
すでにトークンから変数へと処理されているため、関数であれば関数が呼び出され、
変数はenvから呼び出される。
また、要素が一つでない場合は再帰的に処理される。</p>
<pre><code>それぞれの関数の意味は元記事にリストがあるため説明は割愛する。

ここで、envについて説明を行う。

```
class Env(dict):
"環境: ペア{'var':val}のdictで、外部環境(outer)を持つ。"
def __init__(self, parms=(), args=(), outer=None):
    self.update(zip(parms,args))
    self.outer = outer
def find(self, var):
    "var が現れる一番内側のEnvを見つける。"
    return self if var in self else self.outer.find(var)
```

envクラスは、Pythonの辞書を使って定義されたクラスで、辞書のメソッドはそのまま用いることができる。


ここで辞書を使わずにクラスを定義しているのは理由がある。

環境は通常クロージャごとに状態が変わるため、今の環境に値がない場合は、一つ外側の環境にアクセスする必要がある。
findメソッドはそのために定義されたものである。
</code></pre>
</div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"id":"((Pythonで) 書く (Lisp) インタプリタ)","contentHtml":"\u003cp\u003ehttp://www.aoky.net/articles/peter_norvig/lispy.htm より\n記事のまとめ...というより写経。\u003c/p\u003e\n\u003ch2\u003eschemeについて\u003c/h2\u003e\n\u003cp\u003eschemeは一般的にはlispの方言という説明を見かけたが、実態は違う言語である。\nここでlispの方言というのは、内包的な意味ではなく、単純に似た言語であるという意味にちかい。\u003c/p\u003e\n\u003cp\u003e今回の記事では、webページを読んで気づいたこと、写経などを行う。短い記事であるため、早ければ1ページ長くても２ページで終わる予定。\n最終的には記事だけ残る。\u003c/p\u003e\n\u003ch2\u003eインタプリタの作成について\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003eインタプリタは以下のような構成で作成される。\n- 字句解析\n- 構文解析\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e構文実行\n上の二つについてはまとめて論じらることもしばしばあるようだが、大まかにはこれらの大分がされる。\u003c/p\u003e\n\u003cp\u003e字句解析はインタプリタによって大きな違いはなく、与えられた文章を、字句ごとに分けることが目的である。\n構文解析とは、字句解析の段階で最小になった文章の意味づけを理解していくフェーズである。\u003c/p\u003e\n\u003cp\u003eここで、最小に分解された文字を、\u003cstrong\u003eトークン\u003c/strong\u003eと呼ぶ。\n処理されたトークンは、構文解析のフェーズで解読され、最後に構文実行のフェーズで実行される。\nインタプリタの言語ごとの差異は、ここで大きくなる。\u003c/p\u003e\n\u003cp\u003e基本的には、組み込み関数と文、それから式が実行される。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eインタプリタを作成する\u003c/h2\u003e\n\u003ch3\u003e構文解析: readとparse\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003e元の記事では、字句解析と構文解析が一緒くたになっているが、これは字句解析の実装が非常に簡単であったからであると思う。\nというのも、字句解析においてはPythonのstr.splitをそのまま使っている。\n\n```\ndef tokenize(s):\n\"文字列をトークンのリストに変換する。\"\nreturn s.replace('(',' ( ').replace(')',' ) ').split()\n```\nリスト１ 字句解析のプログラム\n\n*()が多いため一見不思議な文に見えるが、()の間に空白を挟んでいるだけである。*\n\n```\ndef read_from(tokens):\n\"トークンの列から式を読み込む。\"\n\tif len(tokens) == 0:\n\t\traise SyntaxError('unexpected EOF while reading')\n\ttoken = tokens.pop(0)\n\tif '(' == token:\n\t\tL = []\n\t\twhile tokens[0] != ')':\n\t\t\tL.append(read_from(tokens))\n\t\ttokens.pop(0) # pop off ')'\n\t\treturn L\n\telif ')' == token:\n\t\traise SyntaxError('unexpected )')\n\telse:\n\t\treturn atom(token)\n\ndef atom(token):\n\"数は数にし、それ以外のトークンはシンボルにする。\"\n\ttry: return int(token)\n\texcept ValueError:\n\t\ttry: return float(token)\n\t\texcept ValueError:\n\t\t\treturn Symbol(token)\n```\nリスト2 構文解析のプログラム\n\nread_from関数は、字句解析されたトークンが入力される。\n\nlispでは、特別な構文は()しかなく、プログラム全体は必ず()に包まれる。\nそれら以外はすべてシンボルか数値である。\n()の中を再帰的に処理し、トークンはそれぞれatom関数でシンボルか数値かどうか判定される。\nシンボルはSymbolというオブジェクトに変換されるが、これはstrのエイリアスでしかなく、実態は後述するenvのなかに辞書の形で格納されている。\nつまりここでSymbolオブジェクトは単なるキーとなる文字列である。\n\n非常に簡素だが、Schemeの構文解析はこのように実装することができる。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e実行: eval\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003edef eval(x, env=global_env):\n    \"環境の中で式を評価する。\"\n    if isa(x, Symbol):             # 変数参照\n        return env.find(x)[x]\n    elif not isa(x, list):         # 定数リテラル\n        return x                \n    elif x[0] == 'quote':          # (quote exp)\n        (_, exp) = x\n        return exp\n    elif x[0] == 'if':             # (if test conseq alt)\n        (_, test, conseq, alt) = x\n        return eval((conseq if eval(test, env) else alt), env)\n    elif x[0] == 'set!':           # (set! var exp)\n        (_, var, exp) = x\n        env.find(var)[var] = eval(exp, env)\n    elif x[0] == 'define':         # (define var exp)\n        (_, var, exp) = x\n        env[var] = eval(exp, env)\n\t\telif x[0] == 'lambda':         # (lambda (var*) exp)\n        (_, vars, exp) = x\n        return lambda *args: eval(exp, Env(vars, args, env))\n    elif x[0] == 'begin':          # (begin exp*)\n        for exp in x[1:]:\n            val = eval(exp, env)\n        return val\n    else:                          # (proc exp*)\n        exps = [eval(exp, env) for exp in x]\n        proc = exps.pop(0)\n        return proc(*exps)\n \nisa = isinstance\n \nSymbol = str\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eリスト3 構文実行のプログラム\u003c/p\u003e\n\u003cp\u003e構文解析によって処理されたプログラムは、ここで解釈される。\nすでにトークンから変数へと処理されているため、関数であれば関数が呼び出され、\n変数はenvから呼び出される。\nまた、要素が一つでない場合は再帰的に処理される。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eそれぞれの関数の意味は元記事にリストがあるため説明は割愛する。\n\nここで、envについて説明を行う。\n\n```\nclass Env(dict):\n\"環境: ペア{'var':val}のdictで、外部環境(outer)を持つ。\"\ndef __init__(self, parms=(), args=(), outer=None):\n    self.update(zip(parms,args))\n    self.outer = outer\ndef find(self, var):\n    \"var が現れる一番内側のEnvを見つける。\"\n    return self if var in self else self.outer.find(var)\n```\n\nenvクラスは、Pythonの辞書を使って定義されたクラスで、辞書のメソッドはそのまま用いることができる。\n\n\nここで辞書を使わずにクラスを定義しているのは理由がある。\n\n環境は通常クロージャごとに状態が変わるため、今の環境に値がない場合は、一つ外側の環境にアクセスする必要がある。\nfindメソッドはそのために定義されたものである。\n\u003c/code\u003e\u003c/pre\u003e\n","title":"((Pythonで) 書く (Lisp) インタプリタ)　を読んで","date":"2022-11-15","tag":"progamming"}},"__N_SSG":true},"page":"/posts/[id]","query":{"id":"((Pythonで) 書く (Lisp) インタプリタ)"},"buildId":"6psNSYDXPa_NtmbTZ86q2","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>